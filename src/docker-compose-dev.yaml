services:
  # this downloads the model once on to host machine and exits
  model-downloader:
    build: 
      context: ./model-downloader
    volumes:
      - ./${DATA_DIR}/models:/root/.cache/huggingface  
    env_file:
      - .env
  
  # llm-server:
  #    image: vllm/vllm-openai:latest
  #    ports:
  #      - "8000:8000"
  #    volumes:
  #      - ~/.cache/huggingface:/root/.cache/huggingface
  #    env_file:
  #      - .env
  #    ipc: "host"
  #    # comment if used in only cpu server environment. 
  #    deploy:
  #      resources:
  #        reservations:
  #          devices:
  #            - capabilities: [gpu]
  #    runtime: nvidia
  #    command: ["--model", "${LLM_MODEL_NAME}", "--dtype", "${DTYPE}"]

  # this embeddings-server is called from the api to generate embeddings
  embeddings-server:
    build: 
      context: ./embeddings-server
      dockerfile: Dockerfile
    #image: rmrhub/sia-embeddings-server:v0.1.1
    environment:
      - PYTHONUNBUFFERED=1
    env_file:
      - .env  # Use environment variables from .env file
    volumes:
      - ./${DATA_DIR}:/${DATA_DIR}  # Mount shared data directory
    depends_on:
      - model-downloader
    ports:
      - "8002:8002"  # Expose port for the embeddings server API    

  # this is the main api-server accessed by the web-server    
  api-server:
    build:
      context: ./api-server
      dockerfile: Dockerfile
    hostname: api-server # required for web-server to proxy_pass
    #image: rmrhub/sia-api-server:v0.1.1
    environment:
      - PYTHONUNBUFFERED=1 # can be removed in production
    env_file:
      - .env
    ports:
      - 8080:8080
    depends_on:
      - embeddings-server
    volumes:
      - ./${DATA_DIR}:/app/${DATA_DIR}  # Shared data directory
  
  web-server:
    build:
      context: ./web-server
      dockerfile: Dockerfile
    image: rmrhub/sia-web-server:v0.1.1
    ports:
      - "3000:3000"
      # Uncomment the following line to expose HTTPS port
      # - "443:443"
    depends_on:
      - api-server
    volumes:
      - ./web-server/nginx.conf:/etc/nginx/nginx.conf:ro
